{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions\n",
    "\n",
    "* This notebook has a combination of fill-in-the-blank and entire code blocks you need to solve. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis Testing\n",
    "\n",
    "\n",
    "We would like to know if the effects we see in the sample(observed data) are likely to occur in the population. \n",
    "\n",
    "The way classical hypothesis testing works is by conducting a statistical test to answer the following question:\n",
    "> Given the sample and an effect, what is the probability of seeing that effect just by chance?\n",
    "\n",
    "Here are the steps on how we would do this\n",
    "\n",
    "1. Compute test statistic\n",
    "2. Define null hypothesis\n",
    "3. Compute p-value\n",
    "4. Interpret the result\n",
    "\n",
    "If p-value is very low (below 0.05), the effect is considered statistically significant. That means that effect is unlikely to have occured by chance. The inference? The effect is likely to be seen in the population too. \n",
    "\n",
    "This process is very similar to the *proof by contradiction* paradigm. We first assume that the effect is false. That's the null hypothesis. Next step is to compute the probability of obtaining that effect (the p-value). If p-value is very low (<0.05 as a rule of thumb), we reject the null hypothesis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import matplotlib as mpl\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set(color_codes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>HighQ</th>\n",
       "      <th>HighQN</th>\n",
       "      <th>MedQ</th>\n",
       "      <th>MedQN</th>\n",
       "      <th>LowQ</th>\n",
       "      <th>LowQN</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>339.06</td>\n",
       "      <td>1042</td>\n",
       "      <td>198.64</td>\n",
       "      <td>933</td>\n",
       "      <td>149.49</td>\n",
       "      <td>123</td>\n",
       "      <td>2014-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>288.75</td>\n",
       "      <td>252</td>\n",
       "      <td>260.60</td>\n",
       "      <td>297</td>\n",
       "      <td>388.58</td>\n",
       "      <td>26</td>\n",
       "      <td>2014-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>303.31</td>\n",
       "      <td>1941</td>\n",
       "      <td>209.35</td>\n",
       "      <td>1625</td>\n",
       "      <td>189.45</td>\n",
       "      <td>222</td>\n",
       "      <td>2014-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>361.85</td>\n",
       "      <td>576</td>\n",
       "      <td>185.62</td>\n",
       "      <td>544</td>\n",
       "      <td>125.87</td>\n",
       "      <td>112</td>\n",
       "      <td>2014-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>248.78</td>\n",
       "      <td>12096</td>\n",
       "      <td>193.56</td>\n",
       "      <td>12812</td>\n",
       "      <td>192.92</td>\n",
       "      <td>778</td>\n",
       "      <td>2014-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        State   HighQ  HighQN    MedQ  MedQN    LowQ  LowQN       date\n",
       "0     Alabama  339.06    1042  198.64    933  149.49    123 2014-01-01\n",
       "1      Alaska  288.75     252  260.60    297  388.58     26 2014-01-01\n",
       "2     Arizona  303.31    1941  209.35   1625  189.45    222 2014-01-01\n",
       "3    Arkansas  361.85     576  185.62    544  125.87    112 2014-01-01\n",
       "4  California  248.78   12096  193.56  12812  192.92    778 2014-01-01"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weed_pd = pd.read_csv(\"../data/Weed_Price.csv\", parse_dates=[-1])\n",
    "weed_pd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Parse the `date` column to create two new columns: one for `month` and one for `year`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Complete the code below\n",
    "\n",
    "weed_pd[\"month\"] = weed_pd['date'].dt.month\n",
    "weed_pd[\"year\"] = weed_pd['date'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>HighQ</th>\n",
       "      <th>HighQN</th>\n",
       "      <th>MedQ</th>\n",
       "      <th>MedQN</th>\n",
       "      <th>LowQ</th>\n",
       "      <th>LowQN</th>\n",
       "      <th>date</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>339.06</td>\n",
       "      <td>1042</td>\n",
       "      <td>198.64</td>\n",
       "      <td>933</td>\n",
       "      <td>149.49</td>\n",
       "      <td>123</td>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>288.75</td>\n",
       "      <td>252</td>\n",
       "      <td>260.60</td>\n",
       "      <td>297</td>\n",
       "      <td>388.58</td>\n",
       "      <td>26</td>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>303.31</td>\n",
       "      <td>1941</td>\n",
       "      <td>209.35</td>\n",
       "      <td>1625</td>\n",
       "      <td>189.45</td>\n",
       "      <td>222</td>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>361.85</td>\n",
       "      <td>576</td>\n",
       "      <td>185.62</td>\n",
       "      <td>544</td>\n",
       "      <td>125.87</td>\n",
       "      <td>112</td>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>248.78</td>\n",
       "      <td>12096</td>\n",
       "      <td>193.56</td>\n",
       "      <td>12812</td>\n",
       "      <td>192.92</td>\n",
       "      <td>778</td>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        State   HighQ  HighQN    MedQ  MedQN    LowQ  LowQN       date  month  \\\n",
       "0     Alabama  339.06    1042  198.64    933  149.49    123 2014-01-01      1   \n",
       "1      Alaska  288.75     252  260.60    297  388.58     26 2014-01-01      1   \n",
       "2     Arizona  303.31    1941  209.35   1625  189.45    222 2014-01-01      1   \n",
       "3    Arkansas  361.85     576  185.62    544  125.87    112 2014-01-01      1   \n",
       "4  California  248.78   12096  193.56  12812  192.92    778 2014-01-01      1   \n",
       "\n",
       "   year  \n",
       "0  2014  \n",
       "1  2014  \n",
       "2  2014  \n",
       "3  2014  \n",
       "4  2014  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weed_pd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's work on weed prices in California in 2014\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Parse the `weed_pd` DataFrame so that it contains only entries for California from 2014."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "weed_ca_2014 = weed_pd[(weed_pd.State == 'California') & (weed_pd.year == 2014)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['California']\n",
      "[2014]\n"
     ]
    }
   ],
   "source": [
    "print(weed_ca_2014['State'].unique())\n",
    "print(weed_ca_2014['year'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Find the mean and standard deviation of high quality weed's price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 245.89423076923077\n",
      "Standard Deviation: 1.2899079393714108\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean:\", weed_ca_2014['HighQ'].mean())\n",
    "print(\"Standard Deviation:\", np.std(weed_ca_2014['HighQ'], ddof=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Calculate the 95% confidence interval on the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m \u001b[0mstats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m\n",
       "Confidence interval with equal areas around the median.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "alpha : array_like of float\n",
       "    Probability that an rv will be drawn from the returned range.\n",
       "    Each value should be in the range [0, 1].\n",
       "arg1, arg2, ... : array_like\n",
       "    The shape parameter(s) for the distribution (see docstring of the\n",
       "    instance object for more information).\n",
       "loc : array_like, optional\n",
       "    location parameter, Default is 0.\n",
       "scale : array_like, optional\n",
       "    scale parameter, Default is 1.\n",
       "\n",
       "Returns\n",
       "-------\n",
       "a, b : ndarray of float\n",
       "    end-points of range that contain ``100 * alpha %`` of the rv's\n",
       "    possible values.\n",
       "\u001b[1;31mFile:\u001b[0m      c:\\users\\mreic_000\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py\n",
       "\u001b[1;31mType:\u001b[0m      method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stats.norm.interval?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(245.7617184927259, 246.02674304573566)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.norm.interval(0.95, loc= weed_ca_2014['HighQ'].mean(), scale = weed_ca_2014.HighQ.std()/np.sqrt(len(weed_ca_2014)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: Are high-quality weed prices in Jan 2014 significantly higher than in Jan 2015?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Make two `numpy` arrays by subetting the original DataFrame: each array should list the `HighQ` entries for California in January of 2014 and 2015."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the data\n",
    "weed_ca_jan2014 = (weed_pd['HighQ'][(weed_pd.State == 'California') & (weed_pd.year == 2014) & (weed_pd.month == 1)]).to_numpy()\n",
    "weed_ca_jan2015 = (weed_pd['HighQ'][(weed_pd.State == 'California') & (weed_pd.year == 2015) & (weed_pd.month == 1)]).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([248.78, 248.67, 248.67, 248.65, 248.68, 248.68, 248.64, 248.63,\n",
       "       248.58, 248.56, 248.54, 248.47, 248.45, 248.41, 248.48, 248.44,\n",
       "       248.43, 248.49, 248.44, 248.39, 248.33, 248.28, 248.25, 248.22,\n",
       "       248.18, 248.21, 248.24, 248.28, 248.23, 248.28, 248.23])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(weed_ca_jan2014))\n",
    "weed_ca_jan2014"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Find the mean value for each of the arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean-2014 Jan: 248.4454838709677\n",
      "Mean-2015 Jan: 243.60225806451612\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean-2014 Jan:\", weed_ca_jan2014.mean())\n",
    "print(\"Mean-2015 Jan:\", weed_ca_jan2015.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Calculate the effect size of one year on the mean value of weed prices in California. What difference does one year make in terms of average weed prices?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effect size: 4.843225806451585\n"
     ]
    }
   ],
   "source": [
    "print(\"Effect size:\", (weed_ca_jan2014.mean() - weed_ca_jan2015.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Null Hypothesis**: Mean prices aren't significantly different\n",
    "\n",
    "Perform **t-test** and determine the p-value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m \u001b[0mstats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mttest_ind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mequal_var\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnan_policy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'propagate'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m\n",
       "Calculate the T-test for the means of *two independent* samples of scores.\n",
       "\n",
       "This is a two-sided test for the null hypothesis that 2 independent samples\n",
       "have identical average (expected) values. This test assumes that the\n",
       "populations have identical variances by default.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "a, b : array_like\n",
       "    The arrays must have the same shape, except in the dimension\n",
       "    corresponding to `axis` (the first, by default).\n",
       "axis : int or None, optional\n",
       "    Axis along which to compute test. If None, compute over the whole\n",
       "    arrays, `a`, and `b`.\n",
       "equal_var : bool, optional\n",
       "    If True (default), perform a standard independent 2 sample test\n",
       "    that assumes equal population variances [1]_.\n",
       "    If False, perform Welch's t-test, which does not assume equal\n",
       "    population variance [2]_.\n",
       "\n",
       "    .. versionadded:: 0.11.0\n",
       "nan_policy : {'propagate', 'raise', 'omit'}, optional\n",
       "    Defines how to handle when input contains nan.\n",
       "    The following options are available (default is 'propagate'):\n",
       "\n",
       "      * 'propagate': returns nan\n",
       "      * 'raise': throws an error\n",
       "      * 'omit': performs the calculations ignoring nan values\n",
       "\n",
       "Returns\n",
       "-------\n",
       "statistic : float or array\n",
       "    The calculated t-statistic.\n",
       "pvalue : float or array\n",
       "    The two-tailed p-value.\n",
       "\n",
       "Notes\n",
       "-----\n",
       "We can use this test, if we observe two independent samples from\n",
       "the same or different population, e.g. exam scores of boys and\n",
       "girls or of two ethnic groups. The test measures whether the\n",
       "average (expected) value differs significantly across samples. If\n",
       "we observe a large p-value, for example larger than 0.05 or 0.1,\n",
       "then we cannot reject the null hypothesis of identical average scores.\n",
       "If the p-value is smaller than the threshold, e.g. 1%, 5% or 10%,\n",
       "then we reject the null hypothesis of equal averages.\n",
       "\n",
       "References\n",
       "----------\n",
       ".. [1] https://en.wikipedia.org/wiki/T-test#Independent_two-sample_t-test\n",
       "\n",
       ".. [2] https://en.wikipedia.org/wiki/Welch%27s_t-test\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> from scipy import stats\n",
       ">>> np.random.seed(12345678)\n",
       "\n",
       "Test with sample with identical means:\n",
       "\n",
       ">>> rvs1 = stats.norm.rvs(loc=5,scale=10,size=500)\n",
       ">>> rvs2 = stats.norm.rvs(loc=5,scale=10,size=500)\n",
       ">>> stats.ttest_ind(rvs1,rvs2)\n",
       "(0.26833823296239279, 0.78849443369564776)\n",
       ">>> stats.ttest_ind(rvs1,rvs2, equal_var = False)\n",
       "(0.26833823296239279, 0.78849452749500748)\n",
       "\n",
       "`ttest_ind` underestimates p for unequal variances:\n",
       "\n",
       ">>> rvs3 = stats.norm.rvs(loc=5, scale=20, size=500)\n",
       ">>> stats.ttest_ind(rvs1, rvs3)\n",
       "(-0.46580283298287162, 0.64145827413436174)\n",
       ">>> stats.ttest_ind(rvs1, rvs3, equal_var = False)\n",
       "(-0.46580283298287162, 0.64149646246569292)\n",
       "\n",
       "When n1 != n2, the equal variance t-statistic is no longer equal to the\n",
       "unequal variance t-statistic:\n",
       "\n",
       ">>> rvs4 = stats.norm.rvs(loc=5, scale=20, size=100)\n",
       ">>> stats.ttest_ind(rvs1, rvs4)\n",
       "(-0.99882539442782481, 0.3182832709103896)\n",
       ">>> stats.ttest_ind(rvs1, rvs4, equal_var = False)\n",
       "(-0.69712570584654099, 0.48716927725402048)\n",
       "\n",
       "T-test with different means, variance, and n:\n",
       "\n",
       ">>> rvs5 = stats.norm.rvs(loc=8, scale=20, size=100)\n",
       ">>> stats.ttest_ind(rvs1, rvs5)\n",
       "(-1.4679669854490653, 0.14263895620529152)\n",
       ">>> stats.ttest_ind(rvs1, rvs5, equal_var = False)\n",
       "(-0.94365973617132992, 0.34744170334794122)\n",
       "\u001b[1;31mFile:\u001b[0m      c:\\users\\mreic_000\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\scipy\\stats\\stats.py\n",
       "\u001b[1;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stats.ttest_ind?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=98.01132523815805, pvalue=6.297971818508403e-68)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.ttest_ind(weed_ca_jan2014, weed_ca_jan2015, equal_var=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p-value is the probability that the effective size was by chance. And here, p-value is almost 0.\n",
    "\n",
    "*Conclusion*: The price difference is significant. But is a price increase of $4.85 a big deal? The price decreased in 2015 by almost 2%. Always remember to look at effect size. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### t-test Challenge\n",
    "**Problem** Determine if prices of medium quality weed for Jan 2015 and Feb 2015 are significantly different for New York. \n",
    "* _**CoderGirl**: Use what you've learned above to answer the below two questions._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "weed_ny_jan2015 = (weed_pd['MedQ'][(weed_pd.State == 'New York') & (weed_pd.year == 2015) & (weed_pd.month == 1)]).to_numpy()\n",
    "weed_ny_feb2015 = (weed_pd['MedQ'][(weed_pd.State == 'New York') & (weed_pd.year == 2015) & (weed_pd.month == 2)]).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effect size: 0.43088709677419956\n"
     ]
    }
   ],
   "source": [
    "print(\"Effect size:\", (weed_ny_jan2015.mean() - weed_ny_feb2015.mean())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=6.889244564601663, pvalue=1.4876340462804882e-08)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.ttest_ind(weed_ny_jan2015, weed_ny_feb2015, equal_var=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assumption of t-test\n",
    "\n",
    "One assumption is that the data used came from a normal distribution. \n",
    "<br>\n",
    "There's a [Shapiro-Wilk test](https://en.wikipedia.org/wiki/Shapiro-Wilk) to test for normality. If p-value is less than 0.05, then there's a low chance that the distribution is normal.\n",
    "\n",
    "* *Are the `weed_ca_jan2015` and `weed_ca_jan2014` data normally distributed?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m \u001b[0mstats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshapiro\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m\n",
       "Perform the Shapiro-Wilk test for normality.\n",
       "\n",
       "The Shapiro-Wilk test tests the null hypothesis that the\n",
       "data was drawn from a normal distribution.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "x : array_like\n",
       "    Array of sample data.\n",
       "\n",
       "Returns\n",
       "-------\n",
       "statistic : float\n",
       "    The test statistic.\n",
       "p-value : float\n",
       "    The p-value for the hypothesis test.\n",
       "\n",
       "See Also\n",
       "--------\n",
       "anderson : The Anderson-Darling test for normality\n",
       "kstest : The Kolmogorov-Smirnov test for goodness of fit.\n",
       "\n",
       "Notes\n",
       "-----\n",
       "The algorithm used is described in [4]_ but censoring parameters as\n",
       "described are not implemented. For N > 5000 the W test statistic is accurate\n",
       "but the p-value may not be.\n",
       "\n",
       "The chance of rejecting the null hypothesis when it is true is close to 5%\n",
       "regardless of sample size.\n",
       "\n",
       "References\n",
       "----------\n",
       ".. [1] https://www.itl.nist.gov/div898/handbook/prc/section2/prc213.htm\n",
       ".. [2] Shapiro, S. S. & Wilk, M.B (1965). An analysis of variance test for\n",
       "       normality (complete samples), Biometrika, Vol. 52, pp. 591-611.\n",
       ".. [3] Razali, N. M. & Wah, Y. B. (2011) Power comparisons of Shapiro-Wilk,\n",
       "       Kolmogorov-Smirnov, Lilliefors and Anderson-Darling tests, Journal of\n",
       "       Statistical Modeling and Analytics, Vol. 2, pp. 21-33.\n",
       ".. [4] ALGORITHM AS R94 APPL. STATIST. (1995) VOL. 44, NO. 4.\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> from scipy import stats\n",
       ">>> np.random.seed(12345678)\n",
       ">>> x = stats.norm.rvs(loc=5, scale=3, size=100)\n",
       ">>> shapiro_test = stats.shapiro(x)\n",
       ">>> shapiro_test\n",
       "ShapiroResult(statistic=0.9772805571556091, pvalue=0.08144091814756393)\n",
       ">>> shapiro_test.statistic\n",
       "0.9772805571556091\n",
       ">>> shapiro_test.pvalue\n",
       "0.08144091814756393\n",
       "\u001b[1;31mFile:\u001b[0m      c:\\users\\mreic_000\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\scipy\\stats\\morestats.py\n",
       "\u001b[1;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stats.shapiro?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ShapiroResult(statistic=0.9458317756652832, pvalue=0.11970169097185135)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.shapiro(weed_ca_jan2015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ShapiroResult(statistic=0.9353488683700562, pvalue=0.06141229346394539)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.shapiro(weed_ca_jan2014)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A/B testing\n",
    "\n",
    "Comparing two versions to check which one performs better. Eg: Show to people two variants for the same webpage that they want to see and find which one provides better conversion rate (or the relevant metric). [wiki](https://en.wikipedia.org/wiki/A/B_testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise: Impact of regulation and deregulation.**\n",
    "\n",
    "* _**CoderGirl**: Use what you've learned above to answer the below two questions._\n",
    "\n",
    "Information on regulation of Weed in the US by State [wiki](Impact of regulation and deregulation on a couple of states )\n",
    "\n",
    "1. Alaska legalized it on 4th Nov 2014. Find if prices significantly changed in Dec 2014 compared to Oct 2014. \n",
    "2. Maryland decriminalized possessing weed from Oct 1, 2014. Find if prices of weed changed significantly in Oct 2014 compared to Sep 2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "weed_alaska_oct2014 = (weed_pd['HighQ'][(weed_pd.State == 'Alaska') & (weed_pd.year == 2014) & (weed_pd.month == 10)]).to_numpy()\n",
    "weed_alaska_dec2014 = (weed_pd['HighQ'][(weed_pd.State == 'Alaska') & (weed_pd.year == 2014) & (weed_pd.month == 12)]).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effect size: 10.28419354838718\n"
     ]
    }
   ],
   "source": [
    "print(\"Effect size:\", (weed_alaska_dec2014.mean() - weed_alaska_oct2014.mean())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=15.14330239573019, pvalue=3.6551929366289856e-22)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.ttest_ind(weed_alaska_dec2014, weed_alaska_oct2014, equal_var=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Something to think about: Which of these give smaller p-values ? </h2>\n",
    "   \n",
    "   * Smaller effect size\n",
    "   * Smaller standard error\n",
    "   * Smaller sample size\n",
    "   * Higher variance\n",
    "   \n",
    "   **Answer:** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p-values tend to become smaller as sample size increases and the sample's effect size remains unchanged\n",
    "# larger sample sizes decrease the margin of error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chi-square tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chi-Square tests are used when the data are frequencies, rather than numerical score/price.\n",
    "\n",
    "The following two tests make use of chi-square statistic\n",
    "\n",
    "1. chi-square test for goodness of fit\n",
    "2. chi-square test for independence\n",
    "\n",
    "Chi-square test is a non-parametric test. They do not require assumptions about population parameters and they do not test hypotheses about population parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Chi-Square test for goodness fit </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\chi^2 = \\sum (O - E)^2/E $$\n",
    "\n",
    "* O is observed frequency\n",
    "* E is expected frequency\n",
    "* $ \\chi $ is the chi-square statistic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's assume the proportion of people who bought High, Medium and Low quality weed in Jan-2014 as the expected proportion. Find if proportion of people who bought weed in Jan 2015 conformed to the norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Find the total numbers of people who bought High/Med/Low quality weed in January of each year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "weed_jan2014 = weed_pd[(weed_pd.year==2014) & (weed_pd.month==1)][[\"HighQN\", \"MedQN\", \"LowQN\"]]\n",
    "weed_jan2015 = weed_pd[(weed_pd.year==2015) & (weed_pd.month==1)][[\"HighQN\", \"MedQN\", \"LowQN\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "Expected = np.array(weed_jan2014.apply(sum, axis=0))\n",
    "Observed = np.array(weed_jan2015.apply(sum, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected: [2918004 2644757  263958] \n",
      " Observed: [4057716 4035049  358088]\n"
     ]
    }
   ],
   "source": [
    "print(\"Expected:\", Expected, \"\\n\" , \"Observed:\", Observed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Print the proportions of High/Med/Low quality weed bought and observed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected: [0.5007971  0.45390159 0.04530131] \n",
      " Observed: [0.48015461 0.47747239 0.042373  ]\n"
     ]
    }
   ],
   "source": [
    "print(\"Expected:\", Expected/np.sum(Expected.astype(float)), \"\\n\" , \"Observed:\", Observed/np.sum(Observed.astype(float)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Do the Chi-Squared test. What is your result? Were the proportions of people buying high quality weed in Jan 2015 different than expected?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m \u001b[0mstats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchisquare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf_obs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf_exp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mddof\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m\n",
       "Calculate a one-way chi-square test.\n",
       "\n",
       "The chi-square test tests the null hypothesis that the categorical data\n",
       "has the given frequencies.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "f_obs : array_like\n",
       "    Observed frequencies in each category.\n",
       "f_exp : array_like, optional\n",
       "    Expected frequencies in each category.  By default the categories are\n",
       "    assumed to be equally likely.\n",
       "ddof : int, optional\n",
       "    \"Delta degrees of freedom\": adjustment to the degrees of freedom\n",
       "    for the p-value.  The p-value is computed using a chi-squared\n",
       "    distribution with ``k - 1 - ddof`` degrees of freedom, where `k`\n",
       "    is the number of observed frequencies.  The default value of `ddof`\n",
       "    is 0.\n",
       "axis : int or None, optional\n",
       "    The axis of the broadcast result of `f_obs` and `f_exp` along which to\n",
       "    apply the test.  If axis is None, all values in `f_obs` are treated\n",
       "    as a single data set.  Default is 0.\n",
       "\n",
       "Returns\n",
       "-------\n",
       "chisq : float or ndarray\n",
       "    The chi-squared test statistic.  The value is a float if `axis` is\n",
       "    None or `f_obs` and `f_exp` are 1-D.\n",
       "p : float or ndarray\n",
       "    The p-value of the test.  The value is a float if `ddof` and the\n",
       "    return value `chisq` are scalars.\n",
       "\n",
       "See Also\n",
       "--------\n",
       "scipy.stats.power_divergence\n",
       "\n",
       "Notes\n",
       "-----\n",
       "This test is invalid when the observed or expected frequencies in each\n",
       "category are too small.  A typical rule is that all of the observed\n",
       "and expected frequencies should be at least 5.\n",
       "\n",
       "The default degrees of freedom, k-1, are for the case when no parameters\n",
       "of the distribution are estimated. If p parameters are estimated by\n",
       "efficient maximum likelihood then the correct degrees of freedom are\n",
       "k-1-p. If the parameters are estimated in a different way, then the\n",
       "dof can be between k-1-p and k-1. However, it is also possible that\n",
       "the asymptotic distribution is not chi-square, in which case this test\n",
       "is not appropriate.\n",
       "\n",
       "References\n",
       "----------\n",
       ".. [1] Lowry, Richard.  \"Concepts and Applications of Inferential\n",
       "       Statistics\". Chapter 8.\n",
       "       https://web.archive.org/web/20171022032306/http://vassarstats.net:80/textbook/ch8pt1.html\n",
       ".. [2] \"Chi-squared test\", https://en.wikipedia.org/wiki/Chi-squared_test\n",
       "\n",
       "Examples\n",
       "--------\n",
       "When just `f_obs` is given, it is assumed that the expected frequencies\n",
       "are uniform and given by the mean of the observed frequencies.\n",
       "\n",
       ">>> from scipy.stats import chisquare\n",
       ">>> chisquare([16, 18, 16, 14, 12, 12])\n",
       "(2.0, 0.84914503608460956)\n",
       "\n",
       "With `f_exp` the expected frequencies can be given.\n",
       "\n",
       ">>> chisquare([16, 18, 16, 14, 12, 12], f_exp=[16, 16, 16, 16, 16, 8])\n",
       "(3.5, 0.62338762774958223)\n",
       "\n",
       "When `f_obs` is 2-D, by default the test is applied to each column.\n",
       "\n",
       ">>> obs = np.array([[16, 18, 16, 14, 12, 12], [32, 24, 16, 28, 20, 24]]).T\n",
       ">>> obs.shape\n",
       "(6, 2)\n",
       ">>> chisquare(obs)\n",
       "(array([ 2.        ,  6.66666667]), array([ 0.84914504,  0.24663415]))\n",
       "\n",
       "By setting ``axis=None``, the test is applied to all data in the array,\n",
       "which is equivalent to applying the test to the flattened array.\n",
       "\n",
       ">>> chisquare(obs, axis=None)\n",
       "(23.31034482758621, 0.015975692534127565)\n",
       ">>> chisquare(obs.ravel())\n",
       "(23.31034482758621, 0.015975692534127565)\n",
       "\n",
       "`ddof` is the change to make to the default degrees of freedom.\n",
       "\n",
       ">>> chisquare([16, 18, 16, 14, 12, 12], ddof=1)\n",
       "(2.0, 0.73575888234288467)\n",
       "\n",
       "The calculation of the p-values is done by broadcasting the\n",
       "chi-squared statistic with `ddof`.\n",
       "\n",
       ">>> chisquare([16, 18, 16, 14, 12, 12], ddof=[0,1,2])\n",
       "(2.0, array([ 0.84914504,  0.73575888,  0.5724067 ]))\n",
       "\n",
       "`f_obs` and `f_exp` are also broadcast.  In the following, `f_obs` has\n",
       "shape (6,) and `f_exp` has shape (2, 6), so the result of broadcasting\n",
       "`f_obs` and `f_exp` has shape (2, 6).  To compute the desired chi-squared\n",
       "statistics, we use ``axis=1``:\n",
       "\n",
       ">>> chisquare([16, 18, 16, 14, 12, 12],\n",
       "...           f_exp=[[16, 16, 16, 16, 16, 8], [8, 20, 20, 16, 12, 12]],\n",
       "...           axis=1)\n",
       "(array([ 3.5 ,  9.25]), array([ 0.62338763,  0.09949846]))\n",
       "\u001b[1;31mFile:\u001b[0m      c:\\users\\mreic_000\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\scipy\\stats\\stats.py\n",
       "\u001b[1;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stats.chisquare?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Power_divergenceResult(statistic=1209562.2775169075, pvalue=0.0)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.chisquare(Observed, Expected, ddof=0, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Inference* : We reject null hypothesis. The proportions in Jan 2015 is different than what was expected."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
